{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_Yiqin Zhang_13061914_&_Haotian Liu_13144744.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/13061914/Assignment-1-Understanding-the-Literature/blob/master/A2_Yiqin_Zhang_13061914_%26_Haotian_Liu_13144744.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xEo23e6b05u",
        "colab_type": "text"
      },
      "source": [
        "# **Assignment 2 Practical Machine Learning Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzqv9VYdgfhA",
        "colab_type": "text"
      },
      "source": [
        "**Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN-diNydgkNK",
        "colab_type": "text"
      },
      "source": [
        "In this project, we chose C4.5 algorithm similar to ID3 algorithm to construct decision tree, it can improve the deficiency of ID3 algorithm to some extent and construct decision tree at the same time. Also, the Classification And Regression Tree (CART) algorithm is used as a backup scheme to compare with C4.5 algorithm. Usually, data can be roughly divided into two categories, one is the number called continuous variable, and the other is the text called discrete variable. According to these two different types of data, decision trees can also be divided into two types of data decision making, regression tree and classification tree. The output results of the two trees are also different. The input data of the regression tree is continuous variable and the output is a real number, while the input data of the classification tree is discrete variable and the output is the prediction category of the sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brv009qugnhM",
        "colab_type": "text"
      },
      "source": [
        "According to feature selection and information gain evaluation, Id3 algorithm takes the feature with the largest gain as the branch standard but cannot process the continuously distributed data features. Therefore, c4.5 algorithm has made targeted improvement on it. In the c4.5 algorithm, the selection of information gain will not be extreme, but more valued attributes will be selected, and continuous attributes can be processed. GINI index is used in CART decision tree to reflect the probability of two random samples in the data set with different categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE959Wv7gpqT",
        "colab_type": "text"
      },
      "source": [
        "**Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1y5PF7YgsY4",
        "colab_type": "text"
      },
      "source": [
        "The data structure of the decision tree is a tree, which is a data set with a tree-like structure. From top to bottom, the root node keeps splitting to produce abstract data types. Each internal node represents a test on an attribute, each branch represents a test output, and each leaf node represents a category. Every node that is not the root node has and has only one parent node, and every node can have a finite number of nodes or no nodes. Since the C4.5 algorithm uses information gain rate to select attributes and establish branches, it is necessary to ensure that all attributes are detected when implementing the algorithm. CART algorithm consists of two parts, the first process is to recursively build a binary tree, then prune it according to the verification data. When constructing binary tree, we need to pay attention to the partition criteria of different attribute data, and when pruning, we need to detect and subtract the unreliable branches. In this project, the cloud environment of Google Colab is used for data storage and calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxNkKOpBguNC",
        "colab_type": "text"
      },
      "source": [
        "C4.5 algorithm processes continuous attributes by converting continuous attributes to discrete attributes before processing. Although the value of the attribute is continuous in nature, it is discrete for limited sampling data. Therefore, we want to select data with continuous attributes and discrete attributes for data modeling and testing. In cart algorithm, if the data types of prediction classification are different, the tree generated is also different. Discrete data generates classification decision tree, and continuous data generates regression decision tree. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptGyhjGJgv6U",
        "colab_type": "text"
      },
      "source": [
        "We found two databases. One data set is census income, which is based on census data to predict whether the income exceeds $50,000 / year. The data features a variety of 14 attributes and 48,842 instances. This database will be used for the C4.5 algorithm. The other is the bank marketing data set on direct marketing calls by banking institutions to predict whether customers will be able to purchase term deposits. The data set is multivariate, with 17 attributes and 45,211 instances, 10% of which will serve as the test set, and the database will be used for CART algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBo6G0VPgxOG",
        "colab_type": "text"
      },
      "source": [
        "**Methodology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tood_bErgzNM",
        "colab_type": "text"
      },
      "source": [
        "***Practical project***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7yXClEcg22w",
        "colab_type": "text"
      },
      "source": [
        "Decision tree is a kind of decision model based on the attributes of data, which can be used to solve classification and regression problems. A decision tree is built for the knowledge information contained in the data and a series of rules and relationships are extracted. The decision tree algorithm needs to solve two major problems, one is the sequence of attribute splitting, the other is when to stop attribute splitting. C4.5 algorithm mainly uses information gain ratio to decide the branches of the tree. Information gain ratio is to find a more appropriate standard to measure data partition by introducing a split information. The more data is divided, the greater the value of the split information, if the value of split information approaches 0, the information gain ratio becomes too large to be trusted. In this project, we used two types of data attributes in the database, so processing the data requires two methods to resolve the data classification. Decision tree visualization is another problem that needs to be solved. When the amount of data is large, it is difficult to observe the unprocessed decision tree. The search results based on the database used are binary, so the tree obtained by CART algorithm, C4.5 algorithm in tree display is difficult to observe. CART algorithm adopts a binary recursive segmentation technique, it calculates GINI coefficient for each sample set partition. the smaller the GINI coefficient, the more reasonable the partition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJCNUdZwg8M-",
        "colab_type": "text"
      },
      "source": [
        "***Algorithm***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoagwjrAg-6G",
        "colab_type": "text"
      },
      "source": [
        "The implementation of the C4.5 algorithm first calculates the information gain rate of each feature, then selects the feature with the highest gain rate, divides the data according to its characteristic value, and then removes the feature selected in the previous step. In each branch dataset, repeat these steps until the dataset cannot or does not need to be partitioned again. The implementation of CART algorithm needs to divide the sample data into two parts in each judgment process and divide the data into the best parts according to the single variable. The key point of cart algorithm is pruning, which can optimize the spanning tree. In this project, the input is a CSV database and the output is a decision tree. Data segmentation is carried out according to the highest information gain ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH1PqdrNhBvm",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpzNMwPzhEQw",
        "colab_type": "text"
      },
      "source": [
        "In this project, C4.5 runs extremely long, more than one hour at a time, and its execution efficiency is very low. Data obtained by CART algorithm is easy to execute and Sklearn model can be called to implement the algorithm and get the tree display. When calculating the database, the accuracy is 89.2%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb4ewmMjhFcI",
        "colab_type": "text"
      },
      "source": [
        "The goal of C4.5 algorithm is to find a mapping relationship from attribute value to category through learning, and this mapping can be used to classify unknown entities of new category. C4.5 algorithm inherits the advantages of ID3 algorithm, algorithm theory is clear, simple method, strong learning ability. In addition, it also optimizes the ID3 algorithm to avoid its disadvantages. In the selection of attributes, it will not favor the attributes with more values, pruning can be carried out in the tree construction, discretization processing can be carried out for the data of continuous attributes, and effective processing can be carried out for the incomplete data. However, its disadvantages are also obvious. In the process of constructing the tree, the data set needs to be scanned and sorted in order for many times, which leads to the inefficiency of the algorithm. In addition, C4.5 is only suitable for data sets that can reside in memory, and programs cannot run when the training set is too large to fit in memory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D-ROMIfhHDI",
        "colab_type": "text"
      },
      "source": [
        "CART decision tree likes C4.5 decision tree, it can easily understand the generation rules and deal with continuous and discrete data attributes. At the same time, it is relatively small computation, can clearly show important fields. However, it also has some disadvantages. When there are too many categories, errors may increase quickly. Also, there is a lot of preprocessing required for data that is chronological."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSgZk4nShIVQ",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPGqeUJkhK1j",
        "colab_type": "text"
      },
      "source": [
        "C4.5 algorithm and CART algorithm are two different methods in calculation, but they have similar points in the implementation process. When the experiment is carried out in the database, the advantages and disadvantages of the two algorithms are very obvious, and the disadvantages of C4.5 algorithm make it difficult to get the results. Therefore, we try to combine cart algorithm with C4.5 algorithm to implement tree display."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8TTzCtVhM43",
        "colab_type": "text"
      },
      "source": [
        "**Ethical**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq6rwJrqhN0C",
        "colab_type": "text"
      },
      "source": [
        "Decision tree is a tree decision graph with additional probabilistic results. Its role is to help predict the outcome and increase the success rate of the outcome. The range of use is very wide, can be used in a variety of different industries, it has been applied in the fields of business, industry, agriculture, astronomy, medicine, risk analysis, social science and taxonomy. If the decision tree is applied to the enterprise, and the scheme is made according to the predicted results, so as to help the enterprise improve its business judgment ability, improve the utilization rate of resources, and reduce the waste of human, material and financial resources. With the continuous improvement and improvement of decision tree algorithm, its application in the society will be more extensive and popular, and it will show its more important practical value in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wc02hM2hrLL",
        "colab_type": "text"
      },
      "source": [
        "**Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4akvNshyp1",
        "colab_type": "text"
      },
      "source": [
        "https://drive.google.com/open?id=1ihnNoCWCE9WP4YlJRIfFhtv7mP9UBNsJ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCU4jN3elnu1",
        "colab_type": "text"
      },
      "source": [
        "**Vidoe Picth**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0wZf9kBlsxl",
        "colab_type": "text"
      },
      "source": [
        "https://youtu.be/DY8sQ4JBzro"
      ]
    }
  ]
}